{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import faiss\n",
    "import lib\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device_ids=list(range(torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This notebook downloads and evaluates 4 checkpoints of UNQ model trained on BIGANN1M and DEEP1M datasets with 8- and 16-byte code sizes. You can also use this code to verify the corrrectness of your setup. If all library versions & hardware are set up properly, the code below should produce the exact same outputs as you can see below. These are also the numbers we report in Table 2 of our paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoint checkpoints/sift_4b/checkpoint_best.pth on dataset BIGANN1M\n",
      "Recall@1  : 0.1001\n",
      "Recall@10 : 0.3392\n",
      "Recall@100: 0.7339\n",
      "Evaluating checkpoint checkpoints/sift_8b/checkpoint_best.pth on dataset BIGANN1M\n",
      "Recall@1  : 0.2837\n",
      "Recall@10 : 0.6915\n",
      "Recall@100: 0.9599\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, checkpoint_path, link in [\n",
    "    ('BIGANN1M', 'checkpoints/sift_4b/checkpoint_best.pth', 'https://www.dropbox.com/s/ycf12yqu5cw4opr/checkpoint_best.pth?dl=1'),\n",
    "    ('BIGANN1M', 'checkpoints/sift_8b/checkpoint_best.pth', 'https://www.dropbox.com/s/y7aucbm5gwyow9r/checkpoint_best.pth?dl=1'),\n",
    "    # ('DEEP1M', 'checkpoints/deep_8b/checkpoint_best.pth', 'https://www.dropbox.com/s/yvtm7y3f3412n9n/checkpoint_best.pth?dl=1'),\n",
    "    # ('DEEP1M', 'checkpoints/deep_16b/checkpoint_best.pth', 'https://www.dropbox.com/s/a0v988tb6i00qir/checkpoint_best.pth?dl=1')\n",
    "]:\n",
    "    print(\"Evaluating checkpoint {} on dataset {}\".format(checkpoint_path, dataset_name))\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "        lib.utils.download(link, checkpoint_path,\n",
    "                 chunk_size=4 * 1024 ** 2)\n",
    "    if '2b' in checkpoint_path:\n",
    "        num_codebooks = 2\n",
    "    elif '4b' in checkpoint_path:\n",
    "        num_codebooks = 4\n",
    "    elif '8b' in checkpoint_path:\n",
    "        num_codebooks = 8\n",
    "    elif '16b' in checkpoint_path:\n",
    "        num_codebooks = 16\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected number of bytes. Make sure you know what you're doing\")\n",
    "\n",
    "    dataset = lib.Dataset(dataset_name, normalize=True)\n",
    "    model = lib.UNQModel(input_dim=dataset.vector_dim, num_codebooks=num_codebooks).cuda()\n",
    "\n",
    "    trainer = lib.Trainer(\n",
    "        model=model, experiment_name='debug', device_ids=device_ids, loss_opts={},\n",
    "        LearnedSimilaritySearch=partial(lib.UNQSearch, model=model, rerank_k=500, batch_size=1000,\n",
    "                                        reorder_batch_size=250, device_ids=device_ids),\n",
    "        NegativeSimilaritySearch=partial(lib.UNQSearch, model=model, rerank_k=1, batch_size=1000,\n",
    "                                        reorder_batch_size=250, device_ids=device_ids),\n",
    "    )\n",
    "    trainer.load_checkpoint(path=checkpoint_path)\n",
    "    print(\"Recall@1  :\", trainer.evaluate_recall(dataset.test_vectors.cuda(), dataset.query_vectors.cuda(), dataset.gt_vectors, k=1))\n",
    "    print(\"Recall@10 :\", trainer.evaluate_recall(dataset.test_vectors.cuda(), dataset.query_vectors.cuda(), dataset.gt_vectors, k=10))\n",
    "    print(\"Recall@100:\", trainer.evaluate_recall(dataset.test_vectors.cuda(), dataset.query_vectors.cuda(), dataset.gt_vectors, k=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
